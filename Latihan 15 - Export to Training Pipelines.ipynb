{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8636f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d178946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2b55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34521 train examples\n",
      "8631 validation examples\n",
      "10788 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed413f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membuat kolom target\n",
    "# 0 = low; 1 = high\n",
    "df['target'] = np.where(df['price'] <= 1000, 0, 1)\n",
    "# Drop un-used columns.\n",
    "df = df.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216f2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cara untuk membuat dataset tf.data dari pandas dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = df.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "batch_size = 10 #bath ukuran kecil untuk demonstrasi\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(train_ds))[0]\n",
    "def demo(feature_column):\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de4571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7 ]\n",
      " [0.7 ]\n",
      " [1.2 ]\n",
      " [1.19]\n",
      " [0.71]\n",
      " [0.71]\n",
      " [0.37]\n",
      " [0.36]\n",
      " [2.01]\n",
      " [1.  ]]\n"
     ]
    }
   ],
   "source": [
    "#numeric column\n",
    "carat = feature_column.numeric_column('carat')\n",
    "demo(carat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47c5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#bucketized column\n",
    "carat = feature_column.numeric_column('carat')\n",
    "carat_buckets = feature_column.bucketized_column(carat, boundaries=[1, 2])\n",
    "demo(carat_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae342eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#categorical\n",
    "color_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'color', ['E', 'I','J','D','H', 'G','F'])\n",
    " \n",
    "color_type_one_hot = feature_column.indicator_column(color_type)\n",
    "demo(color_type_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afaa109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06596094 -0.25000304 -0.09386437 -0.05818721 -0.39615995 -0.5487775 ]\n",
      " [-0.49688536  0.23828071 -0.10483676  0.04456249  0.43668735  0.56724215]\n",
      " [-0.49688536  0.23828071 -0.10483676  0.04456249  0.43668735  0.56724215]\n",
      " [-0.49688536  0.23828071 -0.10483676  0.04456249  0.43668735  0.56724215]\n",
      " [ 0.06596094 -0.25000304 -0.09386437 -0.05818721 -0.39615995 -0.5487775 ]\n",
      " [ 0.22822225  0.2023663  -0.02079243 -0.31212884 -0.24685124 -0.03681855]\n",
      " [-0.49688536  0.23828071 -0.10483676  0.04456249  0.43668735  0.56724215]\n",
      " [ 0.06596094 -0.25000304 -0.09386437 -0.05818721 -0.39615995 -0.5487775 ]\n",
      " [ 0.22822225  0.2023663  -0.02079243 -0.31212884 -0.24685124 -0.03681855]\n",
      " [-0.49688536  0.23828071 -0.10483676  0.04456249  0.43668735  0.56724215]]\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "clarity = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'clarity', df.clarity.unique())\n",
    "clarity_embedding = feature_column.embedding_column(clarity, dimension=6)\n",
    "demo(clarity_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aee61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#hashed feature\n",
    "clarity_hashed = feature_column.categorical_column_with_hash_bucket(\n",
    "      'clarity', hash_bucket_size=5)\n",
    "demo(feature_column.indicator_column(clarity_hashed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfa825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#cross feature\n",
    "#data yang di cross harus berupa string, categorical, atau bucketized\n",
    "crossed_feature = feature_column.crossed_column([carat_buckets, color_type],\n",
    "                                                hash_bucket_size=10)\n",
    "demo(feature_column.indicator_column(crossed_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb660025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pilih feature column mana yang akan digunakan\n",
    "feature_columns = []\n",
    "# numeric column\n",
    "for header in ['carat', 'depth', 'x', 'y', 'z']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    " \n",
    "#membuat feature layer\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0829eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Unnamed: 0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'carat': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'cut': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'color': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'clarity': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'depth': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'table': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'x': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'y': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'z': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Unnamed: 0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'carat': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'cut': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'color': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'clarity': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'depth': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'table': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'x': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'y': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'z': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "1685/1686 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9115WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Unnamed: 0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'carat': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'cut': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'color': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'clarity': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'depth': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'table': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'x': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'y': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'z': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "1686/1686 [==============================] - 29s 4ms/step - loss: 0.2043 - accuracy: 0.9115 - val_loss: 0.1875 - val_accuracy: 0.9277\n",
      "Epoch 2/10\n",
      "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1620 - accuracy: 0.9321 - val_loss: 0.1472 - val_accuracy: 0.9366\n",
      "Epoch 3/10\n",
      "1686/1686 [==============================] - 12s 7ms/step - loss: 0.1537 - accuracy: 0.9345 - val_loss: 0.1439 - val_accuracy: 0.9377\n",
      "Epoch 4/10\n",
      "1686/1686 [==============================] - 12s 7ms/step - loss: 0.1512 - accuracy: 0.9350 - val_loss: 0.1767 - val_accuracy: 0.9348\n",
      "Epoch 5/10\n",
      "1686/1686 [==============================] - 11s 6ms/step - loss: 0.1480 - accuracy: 0.9361 - val_loss: 0.1404 - val_accuracy: 0.9383\n",
      "Epoch 6/10\n",
      "1686/1686 [==============================] - 12s 7ms/step - loss: 0.1465 - accuracy: 0.9372 - val_loss: 0.1416 - val_accuracy: 0.9379\n",
      "Epoch 7/10\n",
      "1686/1686 [==============================] - 10s 6ms/step - loss: 0.1463 - accuracy: 0.9362 - val_loss: 0.1392 - val_accuracy: 0.9380\n",
      "Epoch 8/10\n",
      "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1441 - accuracy: 0.9366 - val_loss: 0.1415 - val_accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "1686/1686 [==============================] - 13s 8ms/step - loss: 0.1434 - accuracy: 0.9373 - val_loss: 0.1385 - val_accuracy: 0.9384\n",
      "Epoch 10/10\n",
      "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1437 - accuracy: 0.9367 - val_loss: 0.1508 - val_accuracy: 0.9389: 2s - - ETA: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4539394c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create, compile, and train the model\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])\n",
    " \n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30837edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
